---
layout: page-sidenav
group: "Chapter. 2"
title: "3. The Gaussian Distribution [II]"
---

- 2.3 절의 가우시안 분포 내용이 너무 길어서 몇 개의 파트로 나누어 설명한다.
- 앞절의 내용은 Part.I 을 참고하기 바란다.

## 2.3.4. 가우시안 MLE (Maximum likelihood for the Gaussian)
- 관찰 데이터 집합 \\( {\bf X}=({\bf x}\_1,...,{\bf x}\_n)^T \\) 가 주어졌을 때 데이터 \\( \{ {\bf x}\_n\} \\) 은 서로 독립적으로 발현된다. (*i.i.d*)
- 각각의 관찰 데이터는 가우시안 분포를 따르게 되며 이를 가능도 함수로 이용할 때에는 보통 로그를 취해 사용하게 된다.

$$\ln p({\bf X}|{\pmb \mu}, \Sigma) = -\frac{ND}{2}\ln(2\pi) - \frac{N}{2}\ln|\Sigma|-\frac{1}{2}\sum_{n=1}^{N}({\bf x}_n-{\pmb \mu})^T\Sigma^{-1}({\bf x}_n-{\pmb \mu}) \qquad{(2.118)}$$

- 이 식은 사실 최종적으로는 다음 두가지 값에만 영향을 받게 된다.

$$\sum_{n=1}^{N}{\bf x}_n \qquad{(2.119)}$$

$$\sum_{n=1}^{N}{\bf x}_n{\bf x}_n^T \qquad{(2.119)}$$

- 이를 충분통계량(*sufficient statistics*)라고 부른다.
- 가우시안 분포를 따르기 때문에 미분을 통해 최대값을 구할 수 있다.

$$\dfrac{\partial}{\partial {\pmb \mu}}\ln p({\bf X}|{\pmb \mu}, \Sigma) = \sum_{n=1}^{N}\Sigma^{-1}({\bf x}_n-{\pmb \mu}) \qquad{(2.120)}$$

- 이 값이 0이 되는 지점에서 최대값을 가지게 된다.
- 따라서 이 때의 평균 값은 다음과 같게 된다.

$${\pmb \mu}_{ML} = \frac{1}{N}\sum_{n=1}^{N}{\bf x}_n \qquad{(2.121)}$$

- 공분산도 별거 없다. 계산의 편리성을 위해 \\( \Lambda=\Sigma^{-1} \\) 로 놓고 풀면 된다.

$$\Sigma_{ML} = \frac{1}{N}\sum_{n=1}{N}({\bf x}-{\pmb \mu}_{ML})({\bf x}-{\pmb \mu}_{ML})^T \qquad{(2.122)}$$ 

- 이 식에서는 \\( {\pmb \mu}\_{ML} \\) 이 사용된다. 먼저 \\( {\pmb \mu}\_{ML} \\) 을 구하고 \\( \Sigma\_{ML} \\) 을 구하면 된다.

- 이 때의 평균 값은 다음과 같다.

$$E[{\pmb \mu}_{ML}] = {\pmb \mu} \qquad{(2.123)}$$

$$E[\Sigma_{ML}] = \frac{N-1}{N}\Sigma \qquad{(2.124)}$$

- 이 내용은 1.2.4 절에서도 다룬 내용이다.
    - MLE의 기대값에 대한 평균은 그냥 평균이 된다. (unbias)
    - 하지만 분산값의 평균은 실제 분산 값보다 작다. (bias)
    - 따라서 보통 이런 요소를 수정해서 분산값으로 다음 값을 사용한다. ( \\( \tilde{\Sigma} \\) 로 표기)

$$\tilde{\Sigma} = \frac{1}{N-1}\sum_{n=1}^{N}({\bf x}_n - {\pmb \mu}_{ML})({\bf x}_n - {\pmb \mu}_{ML})^T \qquad{(2.125)}$$

- 사실 이 내용은 자유도(degree of freedom)와 관련이 깊은 내용이다.
- 통계학 서적을 참고해도 되나 사실 이후 과정을 전개함에 있어 위의 식만 알아도 큰 무리가 없기 때문에, 굳이 찾아서 볼 필요까지는 없다.


----

**(참고)**

- 교재에는 없지만 가우시안 분포에 대한 MLE 유도를 간단히 정리해 놓는다.

*Log Likelihood*

$$\ln p({\bf X}|{\pmb \mu}, \Sigma) = -\frac{ND}{2}\ln(2\pi) - \frac{N}{2}\ln|\Sigma|-\frac{1}{2}\sum_{n=1}^{N}({\bf x}_n-{\pmb \mu})^T\Sigma^{-1}({\bf x}_n-{\pmb \mu})$$

*Basic Equation*

$$\frac{\partial (b^Ta)}{\partial a} = b$$

$$\frac{\partial (a^TAa)}{\partial a} = (A+A^T)a$$

$$\frac{\partial}{\partial A} tr(BA)=B^T$$

$$\frac{\partial}{\partial A} \log|A|=(A^{-1})^T$$

$$tr(ABC)=tr(CAB)=tr(BCA)$$

*Mean*

- \\( {\bf y}=({\bf x}-{\pmb \mu}) \\) 라 하면 다음의 식이 유도된다.

$$\frac{\partial}{\partial {\pmb \mu}}({\bf x}-{\pmb \mu})^T\Sigma^{-1}({\bf x}-{\pmb \mu}) = \frac{\partial}{\partial {\bf y}}{\bf y}^T\Sigma^{-1}{\bf y} \frac{\partial {\bf y}}{\partial {\pmb \mu}} = -(\Sigma^{-1}+(\Sigma^{-1})^{T}){\bf y} \equiv -(\Lambda-\Lambda^T){\bf y}$$

- 따라서

$$\frac{\partial}{\partial {\pmb \mu}}l({\pmb \mu}, \Sigma) = -\frac{1}{2}\sum_{i=1}^{N}-2\Lambda({\bf x}_i-{\pmb \mu})=\Lambda\sum_{i=1}^{N}({\bf x}_i-{\pmb \mu}) = 0$$

- 참고로 공분산은 대칭행렬이라서 위와 같이 전개된다. ( \\( \Sigma^{-1}=(\Sigma^{-1})^T \\))
- 이제 *MLE* 평균은 다음과 같아진다.

$${\pmb \mu}_{ML} = \frac{1}{N}\sum_{i=1}^{N}{\bf x}_i = \bar{\bf x}$$

*Covariance*

- 참고로 \\( \Lambda \equiv \Sigma^{-1} \\) 이고 \\( {\vert}\Lambda{\vert} = {\vert}\Sigma{\vert} \\) 이다.

$$l(\Lambda) = \frac{N}{2}\ln|\Lambda| - \frac{1}{2}\sum_i tr[({\bf x}_i-{\pmb \mu})({\bf x}_i-{\pmb \mu})^T\Lambda] =  \frac{N}{2}\ln|\Lambda| - \frac{1}{2} tr[S_{\mu}\Lambda]$$

$$S_{\mu} = \sum_{i=1}^{N}({\bf x}_i-{\pmb \mu})({\bf x}_i-{\pmb \mu})^T$$

$$\frac{\partial l(\Lambda)}{\partial \Lambda} = \frac{N}{2}(\Lambda^{-1})^{T}-\frac{1}{2}S_{\mu}^T=0$$

$$(\Lambda^{-1})^T = \Lambda^{-1}=\Sigma = \frac{1}{N}S_{\mu}$$

$$\Sigma_{ML} = \frac{1}{N}\sum_{i=1}^{N}({\bf x}_i-\mu)({\bf x}_i-\mu)^T$$


## 2.3.5. 순차 추정 (Sequential estimation)
- 순차 추정의 방법
    - 한번에 한 샘플을 연산하고 버림
    - 관찰 데이터 집합이 매우 커서 한번에 계산이 불가능할 때 사용하기 좋다. (on-memory 불가 상황)

- *MLE* 로 얻어진 \\( {\pmb \mu}_{ML} \\) 식을 업데이트 방식으로 바꾸어보자.
    - \\( {\pmb \mu}_{ML} \\) 에서 마지막 샘플을 추출해보자.
  
$${\pmb \mu}_{ML}^{(N)} = \frac{1}{N} \sum_{n=1}^{N}{\bf x}_n = \frac{1}{N}{\bf x}_N + \frac{1}{N}\sum_{n=1}^{N-1}{\bf x}_n\\
= \frac{1}{N}{\bf x}_N + \frac{N-1}{N}{\pmb \mu}_{ML}^{(N-1)}={\pmb \mu}_{ML}^{(N-1)}+\frac{1}{N}({\bf x}_N-{\pmb \mu}_{ML}^{(N-1)}) \qquad{(2.126)}$$

- \\( N-1 \\) 개의 데이터로부터 추정된 \\( {\pmb \mu}\_{ML}^{(N-1)} \\) 와 \\( N \\) 번째 관측된 데이터를 이용하여 \\( {\pmb \mu}\_{ML}^{(N)} \\) 을 구한다.
- \\( N \\) 의 값이 증가할수록 새로 관측되는 데이터의 기여도가 점점 작아지게 된다.
- 한번에 계산을 처리하는 배치 방식으로부터 식을 유도해 내었기 때문에 실제 결과는 동일하게 된다.
- 이런 방식은 매우 유용하지만 배치 방식의 식에서 업데이트 방식의 식을 항상 유도할 수 있는 것은 아니다.
- 따라서 좀 더 일반화된 방식의 순차 처리 방식에 대해 알아볼 것이다.

-----

**Robbins & Monro** 알고리즘

- 랜덤 변수 \\( \theta \\) 와 \\( z \\) 가 주어졌다고 하자.
- 이 변수들에 대한 결합 분포는 \\( p(z, \theta) \\) 이다.
- \\( \theta \\) 가 주어졌을 때 \\( z \\) 에 대한 평균의 함수를 정의해보자.

$$f(\theta)\equiv E[z|\theta] = \int zp(z|\theta)dz \qquad{(2.127)}$$

- 사실 이러한 형태의 함수를 회귀(regression) 함수라고 한다.
    - 회귀와 관련된 내용은 3장에 더 자세히 나오게 된다.
- 우리의 목표는 \\( f(\theta^{\*}) = 0 \\) 을 만족하는 \\( \theta^{\*} \\) 를 찾는 것이다.
    - 이 때 \\( \theta^* \\) 를 **root** 라고 하자.
    
![figure2.10]({{ site.baseurl }}/images/Figure2.10.png){:class="center-block" height="200px"}

- 여기서 관찰 데이터는 \\( z \\) 이다. (파란색 점)
- \\( z \\) 와 \\( \theta \\) 와 관련된 데이터가 충분히 주어진다면 직접적으로 우리가 원하는 값을 구할 수 있을 것이다.
- 하지만 관찰 데이터가 너무 커서 전체로 주어지지 않고 하나씩 업데이트 된다고 가정해보자.
- 이제 몇 가지 가정을 한다.
    - \\( z \\) 에 대한 조건부 분산(conditional variance)은 유한한 값을 가진다.

$$E[(z-f)^2|\theta]<\infty \qquad{(2.128)}$$

- 또 다른 가정은 다음과 같다.
    - 임의의 \\( \theta \\) 에 대해 \\( \theta > \theta^* \\) 이면 \\( f(\theta) > 0 \\) 
    - 임의의 \\( \theta \\) 에 대해 \\( \theta < \theta^* \\) 이면 \\( f(\theta) < 0 \\)
    - 정확히 그림과 같은 \\( f \\) 함수를 상상하면 된다.
- 이 상황에서 \\( \theta^* \\) 를 추정하는 방법을 생각해보자.

$$\theta^{(N)} = \theta^{(N-1)} - a_{N-1} z(\theta^{N-1}) \qquad{(2.129)}$$

- 이 식을 이용하여 순차적으로 들어오는 데이터를 넣어 root 값을 추정할 수 있다.
    - 이 식이 바로 Robbins & Monro 의 식이다.
- 여기서 \\( z(\theta(N)) \\) 은 \\( N \\) 번째의 \\( \theta \\) 값이 들어왔을 때의 출력값을 의미한다.
- 계수 \\( \{a_N\} \\) 은 연속적인 양의 실수이며 다음과 같은 조건을 만족한다.

$$\lim_{N\rightarrow\infty}a_N=0 \qquad{(2.130)}$$

$$\sum_{N=1}^{\infty}a_N=\infty \qquad{(2.131)}$$

$$\sum_{N-1}^{\infty}a_N^2<\infty \qquad{(2.132)}$$

- 위의 식이 의미하는 바는 다음과 같다.
    - 위의 세 식은 추정이 반복될수록 (즉, \\( N \\) 이 커질수록) 다음의 특성을 갖는다.
        - \\( \lim\_{N\rightarrow\infty}a_N=0 \\) : \\( \theta \\) 가 특정 값에 수렴
        - \\( \sum\_{N=1}^{\infty}a_N=\infty \\) : root 를 찾기도 전에 임의 값에 수렴하지 않도록 
        - \\( \sum\_{N-1}^{\infty}a_N^2<\infty \\) : 축적되는 노이즈가 유한하다는 가정에 의해 수렴된 상태를 깨지 않는다.

- 갑자기 위와 같은 설명이 좀 당황스러울 수도 있지만,
    - Robbins & Monro 가 위의 식이 성립한다는 것을 증명했고,
    - 위와 같은 식 전개를 가우시안 모델에도 그대로 적용하여,
    - 파라미터의 온라인 업데이트가 가능한 모델로 변환할수 있다고 생각하면 된다.

**MLE 적용**

- 가우시안 모델의 MLE를 구하는 과정에서 위의 식을 사용해보자.
- 가우시안 모델에서 \\( \theta_{ML} \\) 의 값은 음의 로그 가능도 함수를 한 번 미분하여 얻을 수 있다.

$$\frac{\partial}{\partial\theta}\left.\left\{-\frac{1}{N}\sum_{n=1}^{N}\ln p(x_n|\theta)\right\}\right|_{\theta_{MLE}}=0 \qquad{(2.133)}$$

- \\( N\rightarrow\infty \\) 로 하여 미분 식과 합의 식을 교환한 뒤 일반화하여 보자.

$$-\lim_{n\rightarrow\infty}\frac{1}{N}\sum_{n=1}^{N}\frac{\partial}{\partial\theta}\ln p(x_n|\theta) = E_x\left[-\frac{\partial}{\partial\theta}\ln p(x|\theta)\right] \qquad{(2.134)}$$

- 이제 Robbins & Monro 의 식과 동일해졌다는 것을 알 수 있다.
    - 가능도 함수의 해를 구하는 것은 회귀 함수의 해를 구하는 문제와 동일하다.
    - 이제 Robbins & Monro 식을 적용해보자.
    
$$\theta^{(N)} = \theta^{(N-1)} - a_{N-1}\frac{\partial}{\partial\theta^{(N-1)}}\left[-\ln p(x_N|\theta^{(N-1)})\right] \qquad{(2.135)}$$

- 겨우 일반화된 식을 만들어내기는 했다.
- 가우시안 분포에서 사용되는 모수는 평균과 분산인데, 평균은 배치 계산 방식에서 순차 계산 방식으로의 변환식을 유도하는 것을 이미 앞서 살펴보았다.
- 하지만 Robbins & Monro 식을 써도 되는걸 이미 알고 있으므로 이제 이 방식으로 변환해 보도록 하자.
    - 그리고 당연히 그 둘의 결과가 동일해야 할 것이다.

- 우선 \\( \ln p(x\_n\|\theta) \\) 는 \\( \ln p(x\_n\|\theta)=\frac{1}{2\sigma^2}(x_n-\theta)^2 \\) 임을 알고 있다.
- 이제 앞서 구한 식에 대입을 하면 다음과 같은 결과를 얻게 된다.

$$z=\frac{\partial}{\partial\mu_{ML}}[-\ln p(x|\mu_{ML}, \sigma^2)]=-\frac{1}{\sigma^2}(x-\mu_{ML}) \qquad{(2.136)}$$

- 우리에게 필요한 식은 \\( E[z\|\theta] \\) 이다.
- 따라서 모든 \\( x \\) 에 대해 평균 공식을 대입하면 \\( -\frac{1}{\sigma^2}(\mu-\mu_{ML}) \\) 을 얻는다.
    - 이는 \\( \frac{1}{N}\sum x_i=\mu \\) 이기 때문이다.

- 사실 \\( E[z\|\theta] \\) 는 회귀 식이므로 \\( z \\) 에 대해 정규분포로 표현이 가능하다.
    - 이 때 이 정규 분포의 평균 값은 실제 회귀 함수가 되며, 따라서 \\( -\frac{1}{\sigma^2}(\mu-\mu_{ML}) \\)
- 정규 분포의 평균 값에 대한 연결선은 직선의 함수가 된다. (붉은색)

![figure2.11]({{ site.baseurl }}/images/Figure2.11.png){:class="center-block" height="200px"}

- 이 때 이 값이 0 을 만족하는 값이 우리가 찾고자 하는 \\( \mu_{ML} \\) 의 해가 된다.
- 여기서 \\( a\_N=\sigma^2/N \\) 으로 놓고 식을 전개하면 배치 방식의 전개와 동일한 식을 얻을 수 있다.
    - 자세한 식 전개는 생략하도록 한다.
    
## 2.3.6. 가우시안에서의 베이지안 추론 (Bayesian inference for the Gaussian)
- 가우시안의 *MLE* 는 파라미터인 평균과 공분산에 대한 점추정(point estimation) 값이다.
- 이제 사전 확률 분포를 추가하여 베이지안 접근 방식으로 이해해 보도록 하자.
- 미리 좀 언급을 해보자면, 다양한 상황의 가우시안 분포가 주어졌을 때 베이지안 추론 방식을 살펴보는 것이다.
    - 분산 값을 알고 있을 때 평균 값의 추론
    - 평균 값을 알고 있을 때 분산 값의 추론
    - 평균, 분산 둘 다 모를 때의 두 값에 대한 추론
    
- 우선 가장 간단한 형태의 식으로부터 학습을 진행해 보도록 한다.
    - 따라서 1차원인 단변량 가우시안 분포부터 시작하도록 한다.

- 우선 가우시안 분포가 하나 주어져있고, 이 때의 분산 값은 이미 알고 있다고 생각한다.
- 데이터는 \\( N \\) 번의 관찰 데이터 \\( {\bf x} = (x\_1,...,x\_N)^T \\) 가 주어졌다.

- 가능도 함수를 구해보자.

$$p({\bf x}|\mu) = \prod_{n=1}^{N}p(x_n|\mu) = \dfrac{1}{(2\pi\sigma^2)^{N/2}}\exp\left\{-\frac{1}{2\sigma^2}\sum_{n=1}^{N}(x_n-\mu)^2\right\} \qquad{(2.137)}$$

- 당연히 이 함수는 \\( \mu \\) 에 대해서는 더 이상 확률 분포가 아니다.
    - 가능도 함수가 반드시 확률 함수가 될 필요는 없다.
- 이 식을 잘 보면 \\( \mu \\) 에 대해 이차형식(`quadrtatic`)의 식이 된다.
- 이제 \\( p(\mu) \\) 에 대해 고민해보자.
    - 당연하겠지만 이 함수는 \\( \mu \\) 의 사전 확률 함수로 공액(`conjugate`) 분포를 사용하게 될 것이다.
    - 따라서 여기서는 당연히 가우시안 분포로 고려한다.
    - 베이지안 추론 방식이 이해되지 않는 경우 별도의 교재를 참고하거나 3장을 살펴보도록 하자.

$$p(\mu) = N(\mu|\mu_0, \sigma_0^2) \qquad{(2.138)}$$

- 이렇게 하면 사후 확률 분포를 다음을 통해 얻을 수 있다.

$$p(\mu|{\bf x}) \propto p({\bf x}|\mu)p(\mu) \qquad{(2.139)}$$

- 이 확률 함수는 공액적 특성에 의해 가우시안 분포가 된다.

$$p(\mu|{\bf x}) = N(\mu|\mu_N, \sigma_N^2) \qquad{(2.140)}$$

- 단,

$$\mu_N = \frac{\sigma^2}{N\sigma_0^2+\sigma^2}\mu_0 + \frac{N\sigma_0^2}{N\sigma_0^2+\sigma^2}\mu_{ML} \qquad{(2.141)}$$

$$\frac{1}{\sigma_N^2}=\frac{1}{\sigma_0^2}+\frac{N}{\sigma^2} \qquad{(2.142)}$$

- 앞서 *MLE* 를 통한 평균 값의 추론 결과는 아래와 같았었다.
    - 위에서 얻어진 평균 식과의 차이가 어떠한지를 생각해보자.

$$\mu_{ML} = \frac{1}{N}\sum_{n=1}^{N}x_n \qquad{(2.143)}$$

- 베이지안 추론을 통해 얻어진 평균값과 분산에 대해 고찰하는 것은 매우 의미있는 일이다.

**사후 확률의 평균**

- 우선 베이지안 추론을 통해 얻어진 사후 확률에 대한 평균값에 대해 생각해 보자.
    - 만약 \\( N \\) 이 \\( N=0 \\) 이라면 평균값은 그냥 \\( \mu_0 \\) 가 된다. (즉, 최초 설정한 평균이 된다.)
    - 만약 \\( N \\) 이 \\( N\rightarrow\infty \\) 라면 평균 값은 결국 *MLE* 의 결과와 같아지게 된다. ( \\( \mu_{N\rightarrow\infty}=\mu\_{ML} \\))

**사후 확률의 분산**

- 이제 베이지안 추론을 통해 얻어진 사후 확률의 분산값에 대해 생각해보자.
    - 만약 \\( N \\) 이 \\( N=0 \\) 이라면 분산도 평균과 마찬가지로 \\( \sigma_0^2 \\) 이 된다.
    - 만약 \\( N \\) 이 \\( N\rightarrow\infty \\) 라면 분산 값은 점점 0에 가까워진다. ( \\( \sigma\_{N\rightarrow\infty}^2=\sigma^2/N \\))
        - 이 의미는 정확도(precision) 가 계속 증가한다는 의미이고,
        - 결국 분포의 모양이 점점 높은 피크를 가지게 된다는 의미가 된다.

![figure2.12]({{ site.baseurl }}/images/Figure2.12.png){:class="center-block" height="200px"}

- 위의 그림은 실제 가우시안 분포를 따르는 확률 분포에 대한 사후 확률 분포를 도식화한 것이다.
- \\( N \\) 이 증가할 수록 분산 값이 작아지는 것을 확인할 수 있다.
- 이를 \\( D \\) 차원의 가우시안 모델에 적용하는 것도 그리 어렵지 않다.

-----

- 우리는 이미 가우시안 분포에서 평균 값을 순차 추정의 식으로 변환하는 것을 살펴보았다.
    - 이 식에서는 입력 데이터 \\( x_N \\) 이 주어졌을 때 \\( N-1 \\) 번째 데이터 관찰된 데이터와의 조합으로 업데이트 식을 작성하였다.
    - 사실 베이지안 패러다임에서는 자연스럽게 이러한 순차 처리 방식을 적용할 수 있도록 해준다. (predictive model)
    - 이를 이용하여 가우시안 평균에 대한 추론 방법을 확인해 보도록 하자.
    - 식에서 우선 \\( x_N \\) 데이터만을 분리하는 과정이 필요하다.

$$p(\mu|{\bf x}) \propto \left[p(\mu)\prod_{n=1}^{N-1}p(x_n|\mu)\right]p(x_N|\mu) \qquad{(2.144)}$$

- 위의 식에서 네모난 영역으로 된 곳이 \\( N-1 \\) 번째 까지의 관찰 데이터에 관한 식이 된다.
    - 물론 위의 식을 그대로 사용하기 위해서는 모든 관찰 데이터는 독립적(i.i.d)으로 생성되어야 한다.
- 어쨌거나 베이지안 추론 방식에서는 구하고자 하는 평균의 값이 점추정 값이 아니라 사후 확률( \\(p(\mu\|{\bf x}) \\) ) 분포로 제공되게 되므로 위의 식을 그대로 업데이트 식으로 사용하면 된다.
    - 만약 평균 값을 점추정하고 싶은 경우 분포식의 평균 값을 사용하면 된다.
    - 현재는 가우시안 분포를 따르므로 최빈값(mode)를 구하거나 평균을 구하거나 얻어지는 값은 동일하다.
    - 공분산의 값은 고정된 값이라 가정하여 식에서 생략했다.

- 다음으로 공분산 추론하는 방법을 알아보도록 한다. 
    - 평균을 구할 때 공분산 값이 고정되어있다고 가정한 것과 마찬가지로 공분산을 추론할 때에는 고정된 평균값이 주어졌다고 가정한다.
    - 계산의 편리성을 위해 다시 한번 공액 사전 분포 (conjugate prior distribution)를 사용한다.
    - 실제 계산에서는 공분산 값을 직접 추론하는 것보다 공분산의 역수, 즉 정확도(precision) \\( \lambda \equiv 1/\sigma^2 \\) 를 구하는게 낫다.

$$p({\bf x}|\lambda) = \prod_{n=1}^{N} N(x_n|\mu, \lambda^{-1}) \propto \lambda^{N/2} \exp\left\{ -\frac{\lambda}{2} \sum_{n=1}^{N}(x_n-\mu)^2\right\} \qquad{(2.145)}$$


- 정확도에 대한 사후 확률 분포에서 사용되는 공액 사전 분포는 **감마** (*gamma*) 분포이다.
- 이에 대한 식은 다음과 같다.

$$Gam(\lambda|a,b)=\frac{1}{\Gamma(a)}b^a\lambda^{a-1}\exp(-b\lambda) \qquad{(2.146)}$$

- 여기서 \\( \Gamma(a) \\) 는 감마 함수로 다음과 같이 정의되어 있다.

$$\Gamma(x) = \int_{0}^{\infty}u^{x-1}e^{-u}du$$

- 감마 분포의 평균과 분산은 다음과 같다.

$$E[\lambda] = \frac{a}{b} \qquad{(2.147)}$$

$$var[\lambda] = \frac{a}{b^2} \qquad{(2.148)}$$

- \\( a \\) 와 \\( b \\) 의 여러 값에 대한 감마 분포를 그림으로 나타내면 다음과 같다.

<div class="text-center">
  <img src="{{ site.baseurl }}/images/Figure2.13a.png" alt="Figure 2.13a" height="150px" />
  <img src="{{ site.baseurl }}/images/Figure2.13b.png" alt="Figure 2.13b" height="150px" />
  <img src="{{ site.baseurl }}/images/Figure2.13b.png" alt="Figure 2.13c" height="150px" />
</div>

- \\( a>0 \\) 인 경우 감마 분포는 유한 적분(finite integral)이며 \\( a \ge 1 \\) 인 경우 분포 자체는 유한값이다.
    - 교재에는 이렇게 간단하게 적혀있으나 이게 무슨 말인지 모르겠다.
        - 실제로 해당 기능을 구현할 때 수렴 여부로 결과 값을 만들 수 있는지 없는지 체크할 때 쓴다는 건 어디서 들었다.
    - 우선 \\( a \ge 1 \\) 여야 \\( \infty \\) 로 수렴하는 값이 없다는 것은 알 수 있다.
    - \\( \Gamma(a) \\) 함수는 \\( a>0 \\) 이어야 유한 적분(finite integral)을 만족한다.
        - 이 부분이 조금 이해가 안된다. 수학적 배경이 있는 듯.
        - 대략적으로 적분 가능 구간이 존재한다는 것은 알 수 있다. (a의 값에 따라 달라진다.)
        - 이후에 이에 대한 전개가 없으므로 그냥 넘어가기로 하자.

-----

- 이제 사전 분포를 \\( Gam(\lambda\|a\_0, b\_0) \\) 로 고려하여 전개한다.
- 그러면 최종적으로 사후 확률을 다음과 같이 얻을 수 있다.

$$p({\bf x}|\lambda) \propto \lambda^{a_0-1}\lambda^{N/2} \exp \left\{-b_0\lambda-\frac{\lambda}{2}\sum_{n=1}^{N}(x_n-\mu)^2\right\} \qquad{(2.149)}$$

- 공액(conjugate)적인 속성에 의해 위의 분포도 감마 분포를 따르게 된다.
    - 이 때의 \\( a \\) 와 \\( b \\) 값을 구해보도록 하자.

$$a_N = a_0 + \frac{N}{2} \qquad{(2.150)}$$

$$b_N = b_0 + \frac{1}{2}\sum_{n=1}^{N}(x_n-\mu)^2 = b_0 + \frac{N}{2}\sigma_{ML}^2 \qquad{(2.151)}$$

- 위의 사후 확률 분포 식을 유심히 보면 정규화를 위한 상수가 생략되어 있는 것을 알 수 있는데, 필요하다면 \\( \Gamma(a_N) \\) 을 이용하여 계산할 수 있다.
- \\( a_N \\) 을 구하는 식으로부터 \\( N \\) 개의 관찰 데이터가 \\( a_N \\) 값에 미치는 영향을 확인해볼 수 있다.
    - \\( a_N \\) 의 식을 보면 \\( N/2 \\) 만큼 값이 보정되고 있다.
    - 만약 \\( N=2a_0 \\) 라면 어떻게 될까? 이러면 \\( a_N = a_0 + \frac{2a_0}{2} = 2a_0 \\) 가 된다. 
        - 즉, 초기 값에서 \\( a_0 \\) 만큼 증가함을 알 수 있음.
    - \\( b_N \\) 도 마찬가지인데 \\( N=2a_0 \\) 라면 사전 확률의 분산 값은 \\( 2b_0/(2a_0)=b_0/a_0 \\) 이고 이를 대입하면 \\( b_N=2b_0 \\) 가 된다.
        - 즉, 초기 값에서 \\( b_0 \\) 만큼 증가함을 알 수 있음
    - 결국 effective number 는 \\( N=2a_0 \\) 지점임
        - 여기서 effective number는 관찰 데이터의 영향력이 지정된 사전 확률의 영향력을 넘어서는 지점에서의 관찰 데이터의 수라고 생각하면 된다.

- 참고로 지금까지 분산을 구하기 위해 정확도(precision)를 이용하여 식을 전개하였는데, 반대로 공분산을 이용하여 식을 전개할수도 있다.
    - 이 때에는 공액 분포로 감마 분포가 아니라 역감마 분포 (*inverse gamma distribution*)를 사용한다.
    
-----

- 이제 평균과 공분산(실제로 구하는 것은 정확도)을 둘 다 모른다고 가정할 때의 파라미터 추정 방식을 살펴보도록 하자.
- 이 때의 공액 사전 분포를 찾기 위해 가능도 함수에서 \\( \mu \\) 과 \\( \lambda \\) 의 의존성을 확인해야 한다.

$$p({\bf x}|\mu, \lambda) = \prod_{n=1}^{N}\left(\frac{\lambda}{2\pi}\right)^{1/2} \exp\left\{-\frac{\lambda}{2}(x_n-\mu)^2\right\}\\
\propto \left[\lambda^{1/2}\exp\left(-\frac{\lambda\mu^2}{2}\right)\right]^N\exp\left\{\lambda\mu\sum_{n=1}^{N}x_n-\frac{\lambda}{2}\sum_{n=1}^{N}x_n^2\right\} \qquad{(2.152)}$$

- 위 식은 가능도 함수로 이로 부터 \\( \mu \\) 와 \\( \lambda \\) 값을 추론해야 한다.
- 식을 완전히 분해할 수는 없고, 식의 전개를 통해 어느 정도 분해를 한다.
- 이제 사전 확률(prior distribution)을 좀 살펴보도록 하자.
    - 여기서 관심을 가져야 하는 모수는 2개. 즉 평균과 분산을 동시에 랜덤 변수로 고려해야 한다.
    - 따라서 사용되는 사전 확률은 \\( p(\mu, \lambda) \\) 가 된다.
    - 원래 공액적 관계를 만들어내기 위해서는 사전 확률의 분포와 사후 확률의 분포를 같도록 만들어야 한다.
    - 여기서는 가능도 함수에 내포된 \\( \mu \\) 와 \\( \lambda \\) 의 함수적인 의존성을 그대로 유지한 사전 분포를 생각해본다.
        - 그냥 가능도 함수 꼴로 사전 분포를 만들어본다는 이야기.
        - 근데 이게 가능한건가 하는 생각이 들기는 하지만 어쨌거나 현재 가우시안 분포를 다루고 있기 때문에,
        - 사전 분포를 가우시안이나 감마 분포의 형태로 취급하는 것도 이상한 것은 아님 (원래 공액 관계의 분포임)
    
$$p(\mu, \lambda) \propto \left[\lambda^{1/2}\exp\left(-\frac{\lambda\mu^2}{2}\right)\right]^\beta\exp\{c\lambda\mu-d\lambda\}\\
= \exp\left\{-\frac{\beta\lambda}{2}(\mu-c/\beta)^2\right\}\lambda^{\beta/2}\exp\left\{-(d-\frac{c^2}{2\beta})\lambda\right\} \qquad{(2.153)}$$

- 가능도 함수 꼴로 만들되 자잘한 상수 값은 항상 동일할 수 없기 때문에 추가적인 상수를 도입한다. ( \\( c \\) , \\( d \\) , \\( \beta \\) )
- 결합 확률 식에 의해 \\( p(\mu, \lambda) = p(\mu\|\lambda)p(\lambda) \\) 가 성립하므로 식을 다음과 같이 기술할 수도 있다.

$$p(\mu, \lambda) = N(\mu|\mu_0, (\beta\lambda)^{-1})Gam(\lambda|a,b) \qquad{(2.154)}$$

- 위의 식을 보아하니 가정한 분포 꼴로 대충 떨어지는 것 같다.
- 각각을 대입하여 전개하면 다음과 같은 식을 얻게 된다.

$$\mu_0 = \frac{c}{\beta}$$

$$a=(1+\beta)/2$$

$$b=d-\frac{c^2}{2\beta}$$

- 이 분포는 *Normal-Gamma* 분포의 형태 꼴이다.
- 이를 도식화하면 다음과 같다.

![figure2.14]({{ site.baseurl }}/images/Figure2.14.png){:class="center-block" height="200px"}

- 위의 그림은 \\( \mu_0=0 \\) , \\( \beta=2 \\) , \\( a=5 \\) , \\( b=6 \\)  일 때의 컨투어이다.

-----

- 만약 1차원이 아니라 \\( D \\) 차원일 때에는 어떻게 처리해야 하나?
    - 사실 별로 어렵지는 않다.
    - 다변량 가우시안 분포 \\( N({\bf x}\|{\pmb \mu}, \Lambda^{-1}) \\) 을 도입하여 전개하면 된다.

- 이 때 사용되는 사전 확률 분포는 다음과 같다.
    
$$W(\Lambda|{\bf W}, v) = B|\Lambda|^{(v-D-1/2)}\exp\left(-\frac{1}{2}Tr({\bf W}^{-1}\Lambda\right) \qquad{(2.155)}$$

- 이런 분포를 위샤트 분포 (*Wishart distribution*)라고 한다.

- 여기서 \\( v \\) 는 자유도(degrees of freedom)라고 하고, \\( {\bf W} \\) 는 \\( D \times D \\) 크기의 행렬이 된다.
- 정규화 상수인 \\( B \\) 는 다음과 같이 정의된다.

$$B({\bf W}, v) = |{\bf W}|^{-v/2}\left(2^{vD/2}\pi^{D(D-1)/4}\prod_{i=1}^{D}\left(\frac{v+1-i}{2}\right)\right)^{-1} \qquad{(2.156)}$$

- 1차식에서와 마찬가지로 정확도 행렬이 아닌 공분산 행렬로 이를 전개 가능하다. 
    - 이 때에는 역 위샤트 분포 (*inverse Wishart distribution*)를 사용해야 한다.

- 앞서 설명한 바와 같이 공액 사전 분포를 다음과 같이 기술할 수도 있다.

$$p({\pmb \mu}, \Lambda|\mu_0, \beta, {\bf W}, v) = N({\pmb \mu}|{\pmb \mu}_0, (\beta\Lambda)^{-1})W(\Lambda|{\bf W}, v)$$

- 이를 *normal-Wishart* 분포 또는 *Gaussian-Wishart* 분포라고 부른다.

-----

- 2.3절의 분량이 너무 길어지는 관계로 이후 절은 Part.III 으로 넘긴다.


